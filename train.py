import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
import pickle
import json
import os

# M1/M2 ë§¥ë¶ì—ì„œ GPU ê°€ì†
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš©!")
else:
    device = torch.device("cpu")
    print("CPU ì‚¬ìš©")

# ğŸ§ª ì‹¤í—˜ 1 ì„¤ì • - HIDDEN_SIZEë§Œ ë³€ê²½
SEQ_LEN = 100      # ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€
HIDDEN_SIZE = 160  # 128 â†’ 160 (ìœ ì¼í•œ ë³€ê²½!)
NUM_LAYERS = 1     # ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€
BATCH_SIZE = 32    # ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€
DROPOUT = 0.2      # ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€
EPOCHS = 10         # ë² ì´ìŠ¤ë¼ì¸ ìœ ì§€
LEARNING_RATE = 0.001

class TrafficDataset(Dataset):
    def __init__(self, data, targets, seq_len=SEQ_LEN):
        self.data = data
        self.targets = targets
        self.seq_len = seq_len
        
    def __len__(self):
        return len(self.data) - self.seq_len
    
    def __getitem__(self, idx):
        x = self.data[idx:idx + self.seq_len]  # ì‹œí€€ìŠ¤ (seq_len, features)
        y = self.targets[idx + self.seq_len]   # peak_volume ê°’
        return torch.FloatTensor(x), torch.FloatTensor([y])

class LSTMModel(pl.LightningModule):
    def __init__(self, input_size, hidden_size=HIDDEN_SIZE, num_layers=1, dropout=0.2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,  # 2ì¸µì¼ ë•Œë§Œ dropout
            bidirectional=False  # ğŸ‘ˆ ì´ê±¸ Falseë¡œ!
        )
        # ì–‘ë°©í–¥ì´ë¯€ë¡œ hidden_size * 2
        self.dropout = nn.Dropout(dropout)
        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)  # 160 -> 80
        self.fc2 = nn.Linear(hidden_size // 2, 1)            # FC 2ì¸µë§Œ!
        self.relu = nn.ReLU()
        
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        last_output = lstm_out[:, -1, :]  # (batch, hidden_size) â† *2 ì œê±°
        x = self.dropout(last_output)
        x = self.relu(self.fc1(x))        # hidden_size â†’ hidden_size // 2
        x = self.dropout(x)               # dropout ì¶”ê°€ë¡œ ì •ê·œí™”
        x = self.fc2(x)                   # hidden_size // 2 â†’ 1 (ìµœì¢… ì¶œë ¥)
        return x
    
    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = nn.L1Loss()(y_hat, y)  # MAEë¡œ ë‹¤ì‹œ
        
        # MAE ê³„ì‚° ë° ë¡œê¹…
        mae = nn.L1Loss()(y_hat, y)
        self.log('train_loss', loss, prog_bar = True)
        self.log('train_mae', mae, prog_bar=True, logger = True)  # ì§„í–‰ë°”ì— í‘œì‹œ
        return loss
    
    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        mae_loss = nn.L1Loss()(y_hat, y)
        
        self.log('val_loss', mae_loss)
        self.log('val_mae', mae_loss, prog_bar=True, logger = True)  # ë™ì¼í•œ ê°’
        return mae_loss
    
    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=LEARNING_RATE)

        # ğŸ†• ì—¬ê¸°ì— ì¶”ê°€!
    def on_train_epoch_end(self):
        train_mae = self.trainer.callback_metrics.get('train_mae', 'N/A')
        print(f"Epoch {self.current_epoch + 1}: Train MAE = {train_mae}")

    def on_validation_epoch_end(self):
        val_mae = self.trainer.callback_metrics.get('val_mae', 'N/A') 
        print(f"Epoch {self.current_epoch + 1}: Val MAE = {val_mae}")

def train_model(model_name="traffic_lstm_v7", 
                csv_path="./task1_data/train_data.csv",
                save_path="./model"):
    os.makedirs(save_path, exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(csv_path)
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
    
    # ì…ë ¥ íŠ¹ì„± (27ê°œ, peak_volume ì œì™¸)
    input_cols = ['fwd_pkt_count', 'bwd_pkt_count', 'fwd_tcp_pkt_count', 'bwd_tcp_pkt_count',
                  'fwd_udp_pkt_count', 'bwd_udp_pkt_count', 'traffic_volume',
                  'fwd_tcp_flags_cwr_count', 'bwd_tcp_flags_cwr_count', 'fwd_tcp_flags_ecn_count',
                  'bwd_tcp_flags_ecn_count', 'fwd_tcp_flags_ack_count', 'bwd_tcp_flags_ack_count',
                  'fwd_tcp_flags_push_count', 'bwd_tcp_flags_push_count', 'fwd_tcp_flags_reset_count',
                  'bwd_tcp_flags_reset_count', 'fwd_tcp_flags_syn_count', 'bwd_tcp_flags_syn_count',
                  'fwd_tcp_flags_fin_count', 'bwd_tcp_flags_fin_count', 'fwd_tcp_window_size_avg',
                  'bwd_tcp_window_size_avg', 'fwd_tcp_window_size_max', 'bwd_tcp_window_size_max',
                  'fwd_tcp_window_size_min', 'bwd_tcp_window_size_min']
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    x_scaler = StandardScaler()
    y_scaler = StandardScaler()
    
    X = x_scaler.fit_transform(df[input_cols].values)  # ì…ë ¥ íŠ¹ì„±
    y = y_scaler.fit_transform(df[['peak_volume']].values).flatten()  # íƒ€ê²Ÿ
    
    # ë°ì´í„° ë¶„í• 
    split = int(len(X) * 0.8)
    X_train, X_val = X[:split], X[split:]
    y_train, y_val = y[:split], y[split:]
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = TrafficDataset(X_train, y_train)
    val_dataset = TrafficDataset(X_val, y_val)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)
    
    # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    model = LSTMModel(len(input_cols), hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)
    trainer = pl.Trainer(
        max_epochs=EPOCHS, 
        enable_progress_bar=True, 
        accelerator="auto",    # ğŸ‘ˆ ì´ê±° ì¶”ê°€
        devices=1              # ğŸ‘ˆ ì´ê±° ì¶”ê°€)
    )
    trainer.fit(model, train_loader, val_loader)
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    model_path = f'{save_path}/{model_name}.pth'
    x_scaler_path = f'{save_path}/{model_name}_scaler.pkl'
    y_scaler_path = f'{save_path}/{model_name}_y_scaler.pkl'
    meta_path = f'{save_path}/{model_name}_meta.json'
    
    # ì €ì¥
    torch.save(model.state_dict(), model_path)
    with open(x_scaler_path, 'wb') as f:
        pickle.dump(x_scaler, f)
    with open(y_scaler_path, 'wb') as f:
        pickle.dump(y_scaler, f)
    
    metadata = {
        'cols': input_cols, 
        'seq_len': SEQ_LEN, 
        'hidden_size': HIDDEN_SIZE,
        'input_size': len(input_cols),
        'num_layers': NUM_LAYERS,    # ìˆ˜ì •
        'dropout': DROPOUT           # ìˆ˜ì •
    }
    with open(meta_path, 'w') as f:
        json.dump(metadata, f)
    
    print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
    print(f"- ëª¨ë¸: {model_path}")
    print(f"- X ìŠ¤ì¼€ì¼ëŸ¬: {x_scaler_path}")
    print(f"- Y ìŠ¤ì¼€ì¼ëŸ¬: {y_scaler_path}")
    print(f"- ë©”íƒ€ë°ì´í„°: {meta_path}")
    return model, x_scaler, y_scaler

if __name__ == "__main__":
    print("=== LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
    model, x_scaler, y_scaler = train_model("traffic_lstm_v7")
    print("=== í•™ìŠµ ì™„ë£Œ! ===")